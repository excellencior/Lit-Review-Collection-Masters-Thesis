## GLaM (Generalist Language Model)
- The largest GLaM has 1.2T parameters which is approximately 7x larger than GPT-3
- Yet, it offers 3x energy efficiency in **training**
- And, 1/2 computation FLOPs for **inference**
- Better overall performance (Zero, One, Few-shot) across 29 NLP tasks


